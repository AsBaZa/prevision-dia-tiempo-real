{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga de datos a PubSub\n",
    "\n",
    "Este notebook se utilizará como una máquina que está cargando datos de forma continua a PubSub.\n",
    "Para conseguir esos datos vamos a coger los datos que se han generado al inicio del curso (datos a nivel día, no datos históricos) y lo vamos a copiarlos en esta carpeta:\n",
    "\n",
    "```\n",
    "prevision-dia-tiempo-real\n",
    "    4. Subiendo la App a Heroku\n",
    "        Subir datos a PubSub\n",
    "            TXT_Simulación_TICKETS_YYYY-MM-DD.txt\n",
    "```\n",
    "\n",
    "\n",
    "Empecemos cargando los datos\n",
    "\n",
    " >- **Nota**: Los datos a introducir tienen que ser del día actual para que el algoritmo funcione. Recordar que esos datos los obtenemos en el paso\n",
    " `0. Pasos previos/1. Generando datos/Scripts R/2 - Creación de Tickets tiempo real`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T13:34:36.700154Z",
     "start_time": "2019-11-27T13:34:36.691156Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "\n",
    "\n",
    "# TODO: Copia el nombre del archivo copiado en esta carpeta\n",
    "nombre_archivo = ''\n",
    "\n",
    "df = pd.read_csv(nombre_archivo, parse_dates=['ticketDate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para continuar, vamos a introducir las credenciales en esta carpeta:\n",
    "\n",
    "```\n",
    "C:\\path_to_repository\\prevision-dia-tiempo-real\\4. Subiendo la App a Heroku\\Subir datos a PubSub /\n",
    "    credentials.json\n",
    "    Carga de datos a PubSub.ipynb\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T13:34:37.196169Z",
     "start_time": "2019-11-27T13:34:37.192176Z"
    }
   },
   "outputs": [],
   "source": [
    "%env GOOGLE_APPLICATION_CREDENTIALS=credentials.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, para lanzar nuestros datos a PubSub, tendremos que volver a especificar el tema y el proyecto que hemos creado en Google Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T13:34:37.659925Z",
     "start_time": "2019-11-27T13:34:37.651945Z"
    }
   },
   "outputs": [],
   "source": [
    "from google.cloud import pubsub_v1\n",
    "\n",
    "# TODO especificar nuestro 'project_id' y 'topic_name'\n",
    "project_id = ''\n",
    "topic_name = ''\n",
    "\n",
    "# Configure the batch to publish as soon as there is one kilobyte\n",
    "# of data or one second has passed.\n",
    "batch_settings = pubsub_v1.types.BatchSettings(\n",
    "    max_bytes=1024,  # One kilobyte\n",
    "    max_latency=1,   # One second\n",
    ")\n",
    "publisher = pubsub_v1.PublisherClient(batch_settings)\n",
    "topic_path = publisher.topic_path(project_id, topic_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que hemos especificado los datos del día, las credenciales y los ID correspondientes, toca subir esos datos. Para ese cometido, vamos a hacerlo en 2 partes:\n",
    "\n",
    " - Para empezar vamos a cargar los datos hasta este instante (hasta el minuto actual en el que ejecutamos el código)\n",
    " - Una vez hemos cargado los datos iniciales, vamos a ir subiendo los datos minuto a minuto (simulando el tiempo real)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a cargar todos los tickets hasta el minuto actual\n",
    "\n",
    " >- **Nota**: Los datos a introducir tienen que ser del día actual para que el algoritmo funcione. Recordar que esos datos los obtenemos en el paso\n",
    " `0. Pasos previos/1. Generando datos/Scripts R/2 - Creación de Tickets tiempo real`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T13:34:41.290506Z",
     "start_time": "2019-11-27T13:34:41.282498Z"
    }
   },
   "outputs": [],
   "source": [
    "def first_load():\n",
    "    now = datetime.now()\n",
    "    now -= timedelta(seconds=now.second)\n",
    "    now -= timedelta(microseconds=now.microsecond)\n",
    "    \n",
    "    df_now = df[df['ticketDate'] <= now]\n",
    "    for index, row in df_now.iterrows():\n",
    "        json_values = {}\n",
    "        json_values['amount'] = row['amount']\n",
    "        json_values['ticketDate'] = row['ticketDate'].strftime('%Y-%m-%d %H:%M:%S')\n",
    "        \n",
    "        # Convertir diccionario en JSON\n",
    "        json_values = json.dumps(json_values)\n",
    "        \n",
    "        # Codificar String\n",
    "        json_values = json_values.encode('utf-8')\n",
    "        future = publisher.publish(topic_path, data=json_values)\n",
    "        \n",
    "    print('Mensajes Publicados')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "para después subirlos minuto a minuto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T13:35:21.081070Z",
     "start_time": "2019-11-27T13:35:21.074061Z"
    }
   },
   "outputs": [],
   "source": [
    "def run():\n",
    "    now = datetime.now()\n",
    "    now -= timedelta(seconds=now.second)\n",
    "    now -= timedelta(microseconds=now.microsecond)\n",
    "    \n",
    "    df_now = df[df['ticketDate'] == now]\n",
    "    for index, row in df_now.iterrows():\n",
    "        json_values = {}\n",
    "        json_values['amount'] = row['amount']\n",
    "        json_values['ticketDate'] = row['ticketDate'].strftime('%Y-%m-%d %H:%M:%S')\n",
    "        \n",
    "        # Convertir diccionario en JSON\n",
    "        json_values = json.dumps(json_values)\n",
    "        \n",
    "        # Codificar String\n",
    "        json_values = json_values.encode('utf-8')\n",
    "        future = publisher.publish(topic_path, data=json_values)\n",
    "        \n",
    "    print('Mensajes Publicados')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para generar un bucle que se repita cada minuto, vamos a utilizar el módulo `APScheduler` de Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T13:35:22.191295Z",
     "start_time": "2019-11-27T13:35:22.186308Z"
    }
   },
   "outputs": [],
   "source": [
    "from apscheduler.schedulers.blocking import BlockingScheduler\n",
    "\n",
    "sched = BlockingScheduler()\n",
    "sched.add_job(run, 'interval', minutes=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecutemos...\n",
    "\n",
    " >- **Nota**: el siguiente bloque va a hacer que Python se meta en un bucle infinito, por lo que si se quiere parar tendremos que darle al botón de `Stop` o reiniciar el `Kernel`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-27T13:35:22.760Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "first_load()\n",
    "sched.start()"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
